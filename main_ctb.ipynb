{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "Oehw8gKj-BQL"
      },
      "outputs": [],
      "source": [
        "USE_LOCAL = False"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "dm2FD59G-I8S"
      },
      "outputs": [],
      "source": [
        "import requests\n",
        "import os\n",
        "from io import BytesIO\n",
        "import shutil\n",
        "if not os.path.exists(\"data\"):\n",
        "    os.makedirs(\"data\")\n",
        "\n",
        "files = [\"CHMF Акции.csv\",\n",
        "         \"MAGN Акции.csv\",\n",
        "         \"NLMK Акции.csv\",\n",
        "         \"test.xlsx\",\n",
        "         \"train.xlsx\",\n",
        "         \"Грузоперевозки.xlsx\",\n",
        "         \"Данные рынка стройматериалов.xlsx\",\n",
        "         \"Индекс LME.xlsx\",\n",
        "         \"Макропоказатели.xlsx\",\n",
        "         \"Показатели рынка металла.xlsx\",\n",
        "         \"Топливо.xlsx\",\n",
        "         \"Цены на сырье.xlsx\"]\n",
        "\n",
        "url = \"https://raw.githubusercontent.com/samoletpanfilov/reinforcement_task/master/data/\"\n",
        "for f in files:\n",
        "    with open(\"data/\"+f, 'wb') as out_file:\n",
        "        shutil.copyfileobj(BytesIO(requests.get(url+f).content), out_file)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Qs92fwXvPEVp",
        "outputId": "5da6d106-ccb5-423d-e3a9-110451674766"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: catboost in /usr/local/lib/python3.11/dist-packages (1.2.7)\n",
            "Requirement already satisfied: gdown in /usr/local/lib/python3.11/dist-packages (5.2.0)\n",
            "Requirement already satisfied: graphviz in /usr/local/lib/python3.11/dist-packages (from catboost) (0.20.3)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.11/dist-packages (from catboost) (3.10.0)\n",
            "Requirement already satisfied: numpy<2.0,>=1.16.0 in /usr/local/lib/python3.11/dist-packages (from catboost) (1.26.4)\n",
            "Requirement already satisfied: pandas>=0.24 in /usr/local/lib/python3.11/dist-packages (from catboost) (2.2.2)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.11/dist-packages (from catboost) (1.14.1)\n",
            "Requirement already satisfied: plotly in /usr/local/lib/python3.11/dist-packages (from catboost) (5.24.1)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.11/dist-packages (from catboost) (1.17.0)\n",
            "Requirement already satisfied: beautifulsoup4 in /usr/local/lib/python3.11/dist-packages (from gdown) (4.13.3)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from gdown) (3.18.0)\n",
            "Requirement already satisfied: requests[socks] in /usr/local/lib/python3.11/dist-packages (from gdown) (2.32.3)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (from gdown) (4.67.1)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas>=0.24->catboost) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas>=0.24->catboost) (2025.1)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas>=0.24->catboost) (2025.1)\n",
            "Requirement already satisfied: soupsieve>1.2 in /usr/local/lib/python3.11/dist-packages (from beautifulsoup4->gdown) (2.6)\n",
            "Requirement already satisfied: typing-extensions>=4.0.0 in /usr/local/lib/python3.11/dist-packages (from beautifulsoup4->gdown) (4.12.2)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib->catboost) (1.3.1)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.11/dist-packages (from matplotlib->catboost) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib->catboost) (4.56.0)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib->catboost) (1.4.8)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib->catboost) (24.2)\n",
            "Requirement already satisfied: pillow>=8 in /usr/local/lib/python3.11/dist-packages (from matplotlib->catboost) (11.1.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib->catboost) (3.2.1)\n",
            "Requirement already satisfied: tenacity>=6.2.0 in /usr/local/lib/python3.11/dist-packages (from plotly->catboost) (9.0.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests[socks]->gdown) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests[socks]->gdown) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests[socks]->gdown) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests[socks]->gdown) (2025.1.31)\n",
            "Requirement already satisfied: PySocks!=1.5.7,>=1.5.6 in /usr/local/lib/python3.11/dist-packages (from requests[socks]->gdown) (1.7.1)\n"
          ]
        }
      ],
      "source": [
        "!pip install catboost gdown"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "j9HfHYODPba8",
        "outputId": "f7ea0db4-8973-40ee-a1c3-e7eafd81750d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Retrieving folder contents\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Retrieving folder 1WOE0meBlVW7435cEzSMYV3qrYkAf6q9X metamodel\n",
            "Processing file 1cdrwrK5mLBpjrfSD_hLT2W8RpYnzvRsd cb_model_1.cbm\n",
            "Processing file 1dgUgUNzHyPqBa9XlwT7oGW7enrGi4XrK cb_model_2.cbm\n",
            "Processing file 1I24pImgbOoWMwkrRFnUIIMurLJ8n4FOC cb_model_3.cbm\n",
            "Processing file 1_acv3ce2Wyu_FMoEzRAYWEh6JVMK8piv cb_model_4.cbm\n",
            "Processing file 1GrUac_STOCA7qVUY0xgY3P2tmrCTEcnA cb_model_5.cbm\n",
            "Processing file 10FBt1VhJ-kfvAlJC-s_3ywVvV6VVM5B8 cb_model_6.cbm\n",
            "Processing file 13OR5M8vHQisS1HGz381Gvv9rPKido9aT cb_model_7.cbm\n",
            "Processing file 16w1X2isZ8lRkhOTvkyew3EPNi-wzdiCU cb_model_8.cbm\n",
            "Processing file 1QQiNWVXNaQ4Hx9XN4yPHimNtH7zb9Me0 cb_model_9.cbm\n",
            "Processing file 1xxxsBt3QhZfQMJPdH9cZcDsvOGG2QH9m metamodel.mmm\n",
            "Processing file 1KYXjI6AplQmS2EjaCJiCYR9whFS84hj3 columns_with_high_nan.txt\n",
            "Processing file 1NwnQKUW2xSLo-QT7W2D2jf6sXxwIye4s sarima_model.pkl\n",
            "Processing file 1FpK5aYYeFcXmLcXqAVWRBWeLC4ybglgR xgb_reg1.pkl\n",
            "Processing file 1BBdcn8aFLONfJLp1sMcZ1IYsTQn1VD5r xgb_reg2.pkl\n",
            "Processing file 1YX_WBfMefjDScuz--_fxAnqlcRD6fIB7 xgb_reg3.pkl\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Retrieving folder contents completed\n",
            "Building directory structure\n",
            "Building directory structure completed\n",
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=1cdrwrK5mLBpjrfSD_hLT2W8RpYnzvRsd\n",
            "To: /content/models/metamodel/cb_model_1.cbm\n",
            "100%|██████████| 1.17M/1.17M [00:00<00:00, 35.5MB/s]\n",
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=1dgUgUNzHyPqBa9XlwT7oGW7enrGi4XrK\n",
            "To: /content/models/metamodel/cb_model_2.cbm\n",
            "100%|██████████| 1.17M/1.17M [00:00<00:00, 121MB/s]\n",
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=1I24pImgbOoWMwkrRFnUIIMurLJ8n4FOC\n",
            "To: /content/models/metamodel/cb_model_3.cbm\n",
            "100%|██████████| 1.17M/1.17M [00:00<00:00, 120MB/s]\n",
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=1_acv3ce2Wyu_FMoEzRAYWEh6JVMK8piv\n",
            "To: /content/models/metamodel/cb_model_4.cbm\n",
            "100%|██████████| 1.17M/1.17M [00:00<00:00, 105MB/s]\n",
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=1GrUac_STOCA7qVUY0xgY3P2tmrCTEcnA\n",
            "To: /content/models/metamodel/cb_model_5.cbm\n",
            "100%|██████████| 1.17M/1.17M [00:00<00:00, 77.5MB/s]\n",
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=10FBt1VhJ-kfvAlJC-s_3ywVvV6VVM5B8\n",
            "To: /content/models/metamodel/cb_model_6.cbm\n",
            "100%|██████████| 1.17M/1.17M [00:00<00:00, 124MB/s]\n",
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=13OR5M8vHQisS1HGz381Gvv9rPKido9aT\n",
            "To: /content/models/metamodel/cb_model_7.cbm\n",
            "100%|██████████| 1.17M/1.17M [00:00<00:00, 112MB/s]\n",
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=16w1X2isZ8lRkhOTvkyew3EPNi-wzdiCU\n",
            "To: /content/models/metamodel/cb_model_8.cbm\n",
            "100%|██████████| 1.17M/1.17M [00:00<00:00, 126MB/s]\n",
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=1QQiNWVXNaQ4Hx9XN4yPHimNtH7zb9Me0\n",
            "To: /content/models/metamodel/cb_model_9.cbm\n",
            "100%|██████████| 1.17M/1.17M [00:00<00:00, 123MB/s]\n",
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=1xxxsBt3QhZfQMJPdH9cZcDsvOGG2QH9m\n",
            "To: /content/models/metamodel/metamodel.mmm\n",
            "100%|██████████| 6.00/6.00 [00:00<00:00, 15.3kB/s]\n",
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=1KYXjI6AplQmS2EjaCJiCYR9whFS84hj3\n",
            "To: /content/models/columns_with_high_nan.txt\n",
            "100%|██████████| 2.35k/2.35k [00:00<00:00, 5.78MB/s]\n",
            "Downloading...\n",
            "From (original): https://drive.google.com/uc?id=1NwnQKUW2xSLo-QT7W2D2jf6sXxwIye4s\n",
            "From (redirected): https://drive.google.com/uc?id=1NwnQKUW2xSLo-QT7W2D2jf6sXxwIye4s&confirm=t&uuid=71cae583-849d-4a73-b7cc-68b8f5b89664\n",
            "To: /content/models/sarima_model.pkl\n",
            "100%|██████████| 542M/542M [00:05<00:00, 106MB/s] \n",
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=1FpK5aYYeFcXmLcXqAVWRBWeLC4ybglgR\n",
            "To: /content/models/xgb_reg1.pkl\n",
            "100%|██████████| 2.46M/2.46M [00:00<00:00, 18.1MB/s]\n",
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=1BBdcn8aFLONfJLp1sMcZ1IYsTQn1VD5r\n",
            "To: /content/models/xgb_reg2.pkl\n",
            "100%|██████████| 2.46M/2.46M [00:00<00:00, 131MB/s]\n",
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=1YX_WBfMefjDScuz--_fxAnqlcRD6fIB7\n",
            "To: /content/models/xgb_reg3.pkl\n",
            "100%|██████████| 2.47M/2.47M [00:00<00:00, 150MB/s]\n",
            "Download completed\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import re\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from catboost import CatBoostRegressor\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "from tqdm import tqdm\n",
        "import os\n",
        "import gdown\n",
        "url = \"https://drive.google.com/drive/folders/1nJZpyxfemM-QwcnsJgdSlEWHGkYH78Cm?usp=sharing\"\n",
        "if not USE_LOCAL:\n",
        "    gdown.download_folder(url, quiet=False, use_cookies=False)\n",
        "\n",
        "horizon = 10\n",
        "month_length = 30\n",
        "inf = 1000000000\n",
        "test_size = 28"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xGD8xFJOPb1O"
      },
      "outputs": [],
      "source": [
        "def load_merge_data() :\n",
        "    df_train = pd.read_excel(\n",
        "    \"data/train.xlsx\").rename(columns={\"dt\": \"timestamp\", \"Цена на арматуру\": \"target\"})\n",
        "    df_test = pd.read_excel(\n",
        "        \"data/test.xlsx\").rename(columns={\"dt\": \"timestamp\", \"Цена на арматуру\": \"target\"})\n",
        "    df_full = pd.concat([df_train, df_test], ignore_index=True)\n",
        "    df_chmf = pd.read_csv(\n",
        "        \"data/CHMF Акции.csv\").rename(columns={\"Date\": \"timestamp\"})\n",
        "    df_magn = pd.read_csv(\n",
        "        \"data/MAGN Акции.csv\").rename(columns={\"Дата\": \"timestamp\"})\n",
        "    df_nlmk = pd.read_csv(\n",
        "        \"data/NLMK Акции.csv\").rename(columns={\"Date\": \"timestamp\"})\n",
        "    df_transfer = pd.read_excel(\"data/Грузоперевозки.xlsx\").rename(\n",
        "        columns={\"dt\": \"timestamp\", \"Индекс стоимости грузоперевозок\": \"transfer_cost\"})\n",
        "    df_market = pd.read_excel(\n",
        "        \"data/Данные рынка стройматериалов.xlsx\").rename(columns={\"dt\": \"timestamp\"})\n",
        "    df_lme = pd.read_excel(\n",
        "        \"data/Индекс LME.xlsx\").rename(columns={\"дата\": \"timestamp\"})\n",
        "    df_macro = pd.read_excel(\n",
        "        \"data/Макропоказатели.xlsx\").rename(columns={\"dt\": \"timestamp\"})\n",
        "    df_fuel = pd.read_excel(\n",
        "        \"data/Топливо.xlsx\").rename(columns={\"dt\": \"timestamp\"})\n",
        "    df_raw_prices = pd.read_excel(\n",
        "        \"data/Цены на сырье.xlsx\").rename(columns={\"dt\": \"timestamp\"})\n",
        "\n",
        "    df_chmf[\"timestamp\"] = pd.to_datetime(df_chmf[\"timestamp\"])\n",
        "    df_magn[\"timestamp\"] = pd.to_datetime(df_magn[\"timestamp\"])\n",
        "    df_nlmk[\"timestamp\"] = pd.to_datetime(df_nlmk[\"timestamp\"])\n",
        "\n",
        "    merged_df = pd.merge(df_full, df_chmf, on='timestamp', how='outer')\n",
        "    merged_df = pd.merge(merged_df, df_magn, on='timestamp', how='outer')\n",
        "    merged_df = pd.merge(merged_df, df_nlmk, on='timestamp', how='outer')\n",
        "    merged_df = pd.merge(merged_df, df_transfer, on='timestamp', how='outer')\n",
        "    merged_df = pd.merge(merged_df, df_market, on='timestamp', how='outer')\n",
        "    merged_df = pd.merge(merged_df, df_lme, on='timestamp', how='outer')\n",
        "    merged_df = pd.merge(merged_df, df_macro, on='timestamp', how='outer')\n",
        "    merged_df = pd.merge(merged_df, df_fuel, on='timestamp', how='outer')\n",
        "    merged_df = pd.merge(merged_df, df_raw_prices, on='timestamp', how='outer')\n",
        "\n",
        "    merged_df = merged_df.sort_values(\"timestamp\")\n",
        "    return merged_df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xBxMZhi_Pjvz"
      },
      "outputs": [],
      "source": [
        "def prepare_data(merged_df):\n",
        "    for window in range(3, 2*month_length):\n",
        "        merged_df['EMA'+str(window)] = merged_df['target'].ewm(alpha=2 / (window + 1), adjust=False).mean()\n",
        "\n",
        "    merged_df = merged_df.dropna(subset=[\"target\"])\n",
        "\n",
        "\n",
        "\n",
        "    for column in merged_df.columns:\n",
        "        if column != \"timestamp\":\n",
        "            if merged_df[column].dtype != float:\n",
        "                merged_df[column] = merged_df[column].apply(lambda x: re.findall(\n",
        "                    r\"[-+]?\\d*\\.\\d+|\\d+\", str(x))[0] if re.findall(r\"[-+]?\\d*\\.\\d+|\\d+\", str(x)) else None)\n",
        "\n",
        "                merged_df[column] = merged_df[column].astype(float)\n",
        "\n",
        "    merged_df[\"timestamp\"] = pd.to_datetime(merged_df[\"timestamp\"])\n",
        "\n",
        "    with open(\"models/columns_with_high_nan.txt\", \"r\", encoding='utf8') as file:\n",
        "        columns_to_drop = file.read().splitlines()\n",
        "\n",
        "    merged_df = merged_df.drop(columns=columns_to_drop)\n",
        "\n",
        "    return merged_df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GjlfgSXcPp7N"
      },
      "outputs": [],
      "source": [
        "def make_data_blocks(df, shift, window):\n",
        "    upgrade_df = df[[\"timestamp\"]].copy()\n",
        "    rga, rgb = shift, shift+window\n",
        "\n",
        "    x = np.array(df[\"target\"]-df[\"target\"].shift(rga)) / 100 # TODO\n",
        "    x = x / (np.abs(x)+1)\n",
        "    upgrade_df[\"target\"] = x\n",
        "\n",
        "    for col in df.columns:\n",
        "        if col !=\"timestamp\":\n",
        "            for i in range(rga, rgb):\n",
        "                col1 = col+str(i)\n",
        "                if i!=rga:\n",
        "                    upgrade_df[col1] = df[col].shift(i)-df[col].shift(rga)\n",
        "                else:\n",
        "                    upgrade_df[col1] = df[col].shift(i)\n",
        "\n",
        "    upgrade_df = upgrade_df[horizon:]\n",
        "    return upgrade_df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YogPq5hKPzo6"
      },
      "outputs": [],
      "source": [
        "def train_test_split(df):\n",
        "    return (df[:-test_size].copy().reset_index(drop=True), df[-test_size:].copy().reset_index(drop=True))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KXE2NfuH-BQP"
      },
      "outputs": [],
      "source": [
        "class model:\n",
        "    def __init__(self, horizon, window, name, is_full_data_train = False):\n",
        "        df = prepare_data(load_merge_data())\n",
        "        upgrade_df = make_data_blocks(df, horizon, window)\n",
        "        if is_full_data_train:\n",
        "            upgrade_train = upgrade_df\n",
        "            upgrade_test = upgrade_df\n",
        "        else:\n",
        "            upgrade_train, upgrade_test = train_test_split(upgrade_df)\n",
        "        self.test_y = upgrade_test['target']\n",
        "        self.test_x = upgrade_test.drop(columns=['target', \"timestamp\"])\n",
        "        self.train_y = upgrade_train['target']\n",
        "        self.train_x = upgrade_train.drop(columns=['target', \"timestamp\"])\n",
        "        self.name = name\n",
        "        self.model = CatBoostRegressor(verbose=0)\n",
        "\n",
        "    def save(self):\n",
        "        self.model.save_model(self.name)\n",
        "\n",
        "    def load(self):\n",
        "\n",
        "        self.model.load_model(self.name)\n",
        "\n",
        "    def fit(self):\n",
        "        self.model = CatBoostRegressor(verbose=0)#, eval_metric = \"R2\")\n",
        "        self.model.fit(self.train_x , self.train_y)\n",
        "\n",
        "    def predict(self):\n",
        "        return self.model.predict(self.test_x)\n",
        "\n",
        "    def true(self):\n",
        "        return self.test_y"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jERU6BYc-BQP"
      },
      "outputs": [],
      "source": [
        "def decision_prices(test):\n",
        "    test = test.set_index('dt')\n",
        "    tender_price = test['Цена на арматуру']\n",
        "    decision = test['Объем']\n",
        "    start_date = test.index.min()\n",
        "    end_date = test.index.max()\n",
        "\n",
        "    _results = []\n",
        "    _active_weeks = 0\n",
        "    for report_date in pd.date_range(start_date, end_date, freq='W-MON'):\n",
        "        if _active_weeks == 0:  # Пришла пора нового тендера\n",
        "            _fixed_price = tender_price.loc[report_date]\n",
        "            _active_weeks = int(decision.loc[report_date])\n",
        "        _results.append(_fixed_price)\n",
        "        _active_weeks += -1\n",
        "    cost = sum(_results)\n",
        "    return cost # Возвращаем затраты на периоде"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5GUMhunI-BQP"
      },
      "outputs": [],
      "source": [
        "class MetaModel:\n",
        "    def __init__(self, window, name):\n",
        "        self.cb_models = []\n",
        "        self.risk_value = 0\n",
        "        self.name = name\n",
        "        self.cnt_models = horizon-1\n",
        "        if not os.path.exists(\"models/\"+ name):\n",
        "            os.mkdir(\"models/\"+ name)\n",
        "        for i in range(1, horizon):\n",
        "            self.cb_models.append(model(i, window, \"models/\"+ name + \"/cb_model_\" + str(i)+\".cbm\"))\n",
        "\n",
        "\n",
        "    def save(self):\n",
        "        for _model in self.cb_models:\n",
        "            _model.save()\n",
        "        with open(\"models/\"+self.name+\"/\"+ self.name+\".mmm\", \"w\", encoding='utf8') as file:\n",
        "            file.write(str(self.risk_value)+\"\\n\")\n",
        "            file.write(str(self.cnt_models)+\"\\n\")\n",
        "\n",
        "\n",
        "    def load(self):\n",
        "        for _model in self.cb_models:\n",
        "            _model.load()\n",
        "        with open(\"models/\"+ self.name+\"/\"+self.name+\".mmm\", \"r\", encoding='utf8') as file:\n",
        "            f = file.read().splitlines()\n",
        "            self.risk_value, self.cnt_models  = float(f[0]), int(f[1])\n",
        "\n",
        "\n",
        "    def __find_suitable_index(self, lst):\n",
        "        for i in range(1, lst.__len__()):\n",
        "            lst[i]= (lst[0]* self.risk_value+lst[i]*(1- self.risk_value))\n",
        "        for i, num in enumerate(lst):\n",
        "            if num < 0:\n",
        "                return i\n",
        "        return len(lst)\n",
        "\n",
        "\n",
        "    def predict(self):\n",
        "        result = []\n",
        "        step = 0\n",
        "        models_predictions = [_model.predict() for _model in self.cb_models]\n",
        "        test_size = models_predictions[0].__len__()\n",
        "        for day_ind in range(test_size):\n",
        "            if step == 0:\n",
        "                segment = [models_predictions[i][day_ind] for i in range(self.cnt_models)]\n",
        "                step = self.__find_suitable_index(segment) + 1\n",
        "                result.append(min(step, test_size - day_ind))\n",
        "            else:\n",
        "                result.append(0)\n",
        "            step-=1\n",
        "        return result"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hbQkuwpYQiI7"
      },
      "outputs": [],
      "source": [
        "window = 6\n",
        "final_model = MetaModel(window, \"metamodel\")\n",
        "final_model.load()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qQ4oHLLfRB8D",
        "outputId": "5214ac56-da68-4f39-d52a-9a261793ed4d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "1 1 1 1 1 1 1 1 1 1 1 1 1 8 0 0 0 0 0 0 0 7 0 0 0 0 0 0\n"
          ]
        }
      ],
      "source": [
        "res = final_model.predict()\n",
        "print(*res)\n",
        "test = pd.read_excel('./data/test.xlsx')\n",
        "test['Объем'] = res\n",
        "test.to_excel('submission.xlsx', index=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Az2gpQ97-BQP",
        "outputId": "58a4d95b-4319-440c-8721-5e908c36e5e5"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "1189100"
            ]
          },
          "execution_count": 14,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "decision_prices(test)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.5"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
