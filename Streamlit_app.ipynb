{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "V28"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "TPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "RvlYkCQ9vFiy"
      },
      "source": [
        "!pip install -q streamlit catboost"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile app.py\n",
        "import streamlit as st\n",
        "import pandas as pd\n",
        "import os\n",
        "import re\n",
        "import numpy as np\n",
        "from catboost import CatBoostRegressor\n",
        "from datetime import datetime\n",
        "\n",
        "# Код из исходного скрипта\n",
        "horizon = 10\n",
        "month_length = 30\n",
        "inf = 1000000000\n",
        "test_size = 28\n",
        "\n",
        "def load_merge_data(dir):\n",
        "    # Исходная функция загрузки данных\n",
        "    df_train = pd.read_excel(\n",
        "        dir+\"/train.xlsx\").rename(columns={\"dt\": \"timestamp\", \"Цена на арматуру\": \"target\"})\n",
        "    df_test = pd.read_excel(\n",
        "        dir+\"/test.xlsx\").rename(columns={\"dt\": \"timestamp\", \"Цена на арматуру\": \"target\"})\n",
        "    df_full = pd.concat([df_train, df_test], ignore_index=True)\n",
        "    df_chmf = pd.read_csv(\n",
        "        dir+\"/CHMF Акции.csv\").rename(columns={\"Date\": \"timestamp\"})\n",
        "    df_magn = pd.read_csv(\n",
        "        dir+\"/MAGN Акции.csv\").rename(columns={\"Дата\": \"timestamp\"})\n",
        "    df_nlmk = pd.read_csv(\n",
        "        dir+\"/NLMK Акции.csv\").rename(columns={\"Date\": \"timestamp\"})\n",
        "    df_transfer = pd.read_excel(dir+\"/Грузоперевозки.xlsx\").rename(\n",
        "        columns={\"dt\": \"timestamp\", \"Индекс стоимости грузоперевозок\": \"transfer_cost\"})\n",
        "    df_market = pd.read_excel(\n",
        "        dir+\"/Данные рынка стройматериалов.xlsx\").rename(columns={\"dt\": \"timestamp\"})\n",
        "    df_lme = pd.read_excel(\n",
        "        dir+\"/Индекс LME.xlsx\").rename(columns={\"дата\": \"timestamp\"})\n",
        "    df_macro = pd.read_excel(\n",
        "        dir+\"/Макропоказатели.xlsx\").rename(columns={\"dt\": \"timestamp\"})\n",
        "    df_fuel = pd.read_excel(\n",
        "        dir+\"/Топливо.xlsx\").rename(columns={\"dt\": \"timestamp\"})\n",
        "    df_raw_prices = pd.read_excel(\n",
        "        dir+\"/Цены на сырье.xlsx\").rename(columns={\"dt\": \"timestamp\"})\n",
        "\n",
        "    df_chmf[\"timestamp\"] = pd.to_datetime(df_chmf[\"timestamp\"])\n",
        "    df_magn[\"timestamp\"] = pd.to_datetime(df_magn[\"timestamp\"])\n",
        "    df_nlmk[\"timestamp\"] = pd.to_datetime(df_nlmk[\"timestamp\"])\n",
        "\n",
        "    merged_df = pd.merge(df_full, df_chmf, on='timestamp', how='outer')\n",
        "    merged_df = pd.merge(merged_df, df_magn, on='timestamp', how='outer')\n",
        "    merged_df = pd.merge(merged_df, df_nlmk, on='timestamp', how='outer')\n",
        "    merged_df = pd.merge(merged_df, df_transfer, on='timestamp', how='outer')\n",
        "    merged_df = pd.merge(merged_df, df_market, on='timestamp', how='outer')\n",
        "    merged_df = pd.merge(merged_df, df_lme, on='timestamp', how='outer')\n",
        "    merged_df = pd.merge(merged_df, df_macro, on='timestamp', how='outer')\n",
        "    merged_df = pd.merge(merged_df, df_fuel, on='timestamp', how='outer')\n",
        "    merged_df = pd.merge(merged_df, df_raw_prices, on='timestamp', how='outer')\n",
        "\n",
        "    return merged_df.sort_values(\"timestamp\")\n",
        "\n",
        "def prepare_data(merged_df):\n",
        "    # Исходная функция подготовки данных\n",
        "    for window in range(3, 2*month_length):\n",
        "        merged_df['EMA'+str(window)] = merged_df['target'].ewm(alpha=2 / (window + 1), adjust=False).mean()\n",
        "\n",
        "    merged_df = merged_df.dropna(subset=[\"target\"])\n",
        "\n",
        "    for column in merged_df.columns:\n",
        "        if column != \"timestamp\":\n",
        "            if merged_df[column].dtype != float:\n",
        "                merged_df[column] = merged_df[column].apply(lambda x: re.findall(\n",
        "                    r\"[-+]?\\d*\\.\\d+|\\d+\", str(x))[0] if re.findall(r\"[-+]?\\d*\\.\\d+|\\d+\", str(x)) else None)\n",
        "                merged_df[column] = merged_df[column].astype(float)\n",
        "\n",
        "    merged_df[\"timestamp\"] = pd.to_datetime(merged_df[\"timestamp\"])\n",
        "\n",
        "    with open(\"models/columns_with_high_nan.txt\", \"r\", encoding='utf8') as file:\n",
        "        columns_to_drop = file.read().splitlines()\n",
        "\n",
        "    return merged_df.drop(columns=columns_to_drop)\n",
        "\n",
        "def make_data_blocks(df, shift, window):\n",
        "    # Исходная функция создания блоков данных\n",
        "    upgrade_df = df[[\"timestamp\"]].copy()\n",
        "    rga, rgb = shift, shift+window\n",
        "\n",
        "    x = np.array(df[\"target\"]-df[\"target\"].shift(rga)) / 100\n",
        "    x = x / (np.abs(x)+1)\n",
        "    upgrade_df[\"target\"] = x\n",
        "\n",
        "    for col in df.columns:\n",
        "        if col !=\"timestamp\":\n",
        "            for i in range(rga, rgb):\n",
        "                col1 = col+str(i)\n",
        "                if i!=rga:\n",
        "                    upgrade_df[col1] = df[col].shift(i)-df[col].shift(rga)\n",
        "                else:\n",
        "                    upgrade_df[col1] = df[col].shift(i)\n",
        "\n",
        "    return upgrade_df[horizon:]\n",
        "\n",
        "def train_test_split(df):\n",
        "    return (df[:-test_size].copy().reset_index(drop=True), df[-test_size:].copy().reset_index(drop=True))\n",
        "\n",
        "class model:\n",
        "    # Исходный класс модели\n",
        "    def __init__(self, horizon, window, name, feat_dir, is_full_data_train=False):\n",
        "        df = prepare_data(load_merge_data(feat_dir))\n",
        "        upgrade_df = make_data_blocks(df, horizon, window)\n",
        "        if is_full_data_train:\n",
        "            upgrade_train = upgrade_df\n",
        "            upgrade_test = upgrade_df\n",
        "        else:\n",
        "            upgrade_train, upgrade_test = train_test_split(upgrade_df)\n",
        "        self.test_y = upgrade_test['target']\n",
        "        self.test_x = upgrade_test.drop(columns=['target', \"timestamp\"])\n",
        "        self.train_y = upgrade_train['target']\n",
        "        self.train_x = upgrade_train.drop(columns=['target', \"timestamp\"])\n",
        "        self.name = name\n",
        "        self.model = CatBoostRegressor(verbose=0)\n",
        "\n",
        "    def load(self):\n",
        "        self.model.load_model(self.name)\n",
        "\n",
        "    def predict(self):\n",
        "        return self.model.predict(self.test_x)\n",
        "\n",
        "class MetaModel:\n",
        "    # Исходный класс метамодели\n",
        "    def __init__(self, window, model_path, feat_dir, name):\n",
        "        self.cb_models = []\n",
        "        self.risk_value = 0\n",
        "        self.name = name\n",
        "        self.cnt_models = horizon-1\n",
        "        for i in range(1, horizon):\n",
        "            m = model(i, window, model_path+\"/models/\"+ name + \"/cb_model_\" + str(i)+\".cbm\",feat_dir)\n",
        "            m.load()\n",
        "            self.cb_models.append(m)\n",
        "\n",
        "    def __find_suitable_index(self, lst):\n",
        "        for i in range(1, len(lst)):\n",
        "            lst[i]= (lst[0]* self.risk_value+lst[i]*(1- self.risk_value))\n",
        "        for i, num in enumerate(lst):\n",
        "            if num < 0:\n",
        "                return i\n",
        "        return len(lst)\n",
        "\n",
        "    def predict(self):\n",
        "        result = []\n",
        "        step = 0\n",
        "        models_predictions = [_model.predict() for _model in self.cb_models]\n",
        "        test_size = len(models_predictions[0])\n",
        "        for day_ind in range(test_size):\n",
        "            if step == 0:\n",
        "                segment = [models_predictions[i][day_ind] for i in range(self.cnt_models)]\n",
        "                step = self.__find_suitable_index(segment) + 1\n",
        "                result.append(min(step, test_size - day_ind))\n",
        "            else:\n",
        "                result.append(0)\n",
        "            step-=1\n",
        "        return result\n",
        "\n",
        "def make_prediction(model_path, features_dir, result_file, purchase_date):\n",
        "    window = 10\n",
        "    final_model = MetaModel(window, model_path, features_dir, \"metamodel\")\n",
        "    purchase_date = pd.to_datetime(purchase_date)\n",
        "    res = pd.read_excel(result_file)\n",
        "    res['Объем'] = final_model.predict()\n",
        "    return (res[res['dt']==purchase_date]['Объем']).values[0]\n",
        "\n",
        "st.title('Прогнозирование сроков закупки арматуры')\n",
        "st.write(\"Загрузите необходимые файлы данных:\")\n",
        "\n",
        "os.makedirs(\"data\", exist_ok=True)\n",
        "os.makedirs(\"models\", exist_ok=True)\n",
        "\n",
        "required_files = {\n",
        "    'train.xlsx': 'xlsx',\n",
        "    'test.xlsx': 'xlsx',\n",
        "    'CHMF Акции.csv': 'csv',\n",
        "    'MAGN Акции.csv': 'csv',\n",
        "    'NLMK Акции.csv': 'csv',\n",
        "    'Грузоперевозки.xlsx': 'xlsx',\n",
        "    'Данные рынка стройматериалов.xlsx': 'xlsx',\n",
        "    'Индекс LME.xlsx': 'xlsx',\n",
        "    'Макропоказатели.xlsx': 'xlsx',\n",
        "    'Топливо.xlsx': 'xlsx',\n",
        "    'Цены на сырье.xlsx': 'xlsx'\n",
        "}\n",
        "\n",
        "uploaded_files = st.file_uploader(\"Выберите файлы\", type=[\"xlsx\", \"csv\"], accept_multiple_files=True)\n",
        "\n",
        "if uploaded_files:\n",
        "    for file in uploaded_files:\n",
        "        with open(os.path.join(\"data\", file.name), \"wb\") as f:\n",
        "            f.write(file.getbuffer())\n",
        "    st.success(\"Файлы успешно загружены!\")\n",
        "\n",
        "all_files_uploaded = all(os.path.exists(os.path.join(\"data\", f)) for f in required_files.keys())\n",
        "\n",
        "if all_files_uploaded:\n",
        "    try:\n",
        "        test_df = pd.read_excel(\"data/test.xlsx\")\n",
        "        dates = pd.to_datetime(test_df['dt']).dt.date\n",
        "        min_date = min(dates)\n",
        "        max_date = max(dates)\n",
        "\n",
        "        selected_date = st.date_input(\n",
        "            \"Выберите дату закупки\",\n",
        "            min_value=min_date,\n",
        "            max_value=max_date,\n",
        "            value=min_date\n",
        "        )\n",
        "\n",
        "        if st.button(\"Рассчитать срок закупки\"):\n",
        "            prediction = make_prediction(\n",
        "                model_path=\".\",\n",
        "                features_dir=\"data\",\n",
        "                result_file=\"data/test.xlsx\",\n",
        "                purchase_date=selected_date.strftime(\"%Y-%m-%d\")\n",
        "            )\n",
        "            st.success(f\"Рекомендуемый срок закупки: {prediction} недель\")\n",
        "    except Exception as e:\n",
        "        st.error(f\"Ошибка: {str(e)}\")\n",
        "else:\n",
        "    st.warning(\"Пожалуйста, загрузите все необходимые файлы:\")\n",
        "    for fname in required_files:\n",
        "        st.write(f\"- {fname}\")"
      ],
      "metadata": {
        "id": "meJ36PefNftd",
        "outputId": "e8f43f3f-5a2f-4fb0-e34c-a4faac2d9d72",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Overwriting app.py\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7bec11bb-d15d-4bb4-9948-e03f9f021433",
        "id": "ZAyqQCQVOoxC"
      },
      "source": [
        "!npm install localtunnel"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1G\u001b[0K⠙\u001b[1G\u001b[0K⠹\u001b[1G\u001b[0K⠸\u001b[1G\u001b[0K⠼\u001b[1G\u001b[0K⠴\u001b[1G\u001b[0K⠦\u001b[1G\u001b[0K⠧\u001b[1G\u001b[0K\n",
            "up to date, audited 23 packages in 1s\n",
            "\u001b[1G\u001b[0K⠧\u001b[1G\u001b[0K\n",
            "\u001b[1G\u001b[0K⠧\u001b[1G\u001b[0K3 packages are looking for funding\n",
            "\u001b[1G\u001b[0K⠧\u001b[1G\u001b[0K  run `npm fund` for details\n",
            "\u001b[1G\u001b[0K⠧\u001b[1G\u001b[0K\n",
            "2 \u001b[31m\u001b[1mhigh\u001b[22m\u001b[39m severity vulnerabilities\n",
            "\n",
            "To address all issues (including breaking changes), run:\n",
            "  npm audit fix --force\n",
            "\n",
            "Run `npm audit` for details.\n",
            "\u001b[1G\u001b[0K⠧\u001b[1G\u001b[0K"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!streamlit run /content/app.py &>/content/logs.txt &"
      ],
      "metadata": {
        "id": "Zv912rRAN0fs"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!npx localtunnel --port 8501 & curl ipv4.icanhazip.com"
      ],
      "metadata": {
        "id": "XTGAizLhOIgC",
        "outputId": "fab49ccf-d08f-478f-becb-59b946f6984d",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "34.121.116.255\n",
            "\u001b[1G\u001b[0K⠙\u001b[1G\u001b[0Kyour url is: https://olive-mirrors-tickle.loca.lt\n"
          ]
        }
      ]
    }
  ]
}